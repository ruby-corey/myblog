import torch
from vit_pytorch import ViT
import torch.nn.functional as F

model = ViT(
    image_size=32,
    patch_size=4,
    num_classes=10,
    dim=128,
    depth=4,
    heads=4,
    mlp_dim=256,
    dropout=0.1,
    emb_dropout=0.1
)
model.load_state_dict(torch.load('./weight/vit_model_1.pth', map_location=torch.device('cuda')))
# torch.loadæ˜¯åŠ è½½é¢„è®­ç»ƒçš„æ¨¡å‹æƒé‡ï¼ˆè¿™äº›æƒé‡é€šå¸¸ä¿å­˜åœ¨å­—å…¸ä¸­ï¼‰ load_state_dictåŠ è½½åˆ°æ¨¡å‹ä¸­
model.eval()

from PIL import Image
from torchvision.transforms import transforms

transform = transforms.Compose(
    [transforms.Resize((32, 32)),
     transforms.ToTens20or(),  # transforms.ToTensor() å°†å›¾åƒæ ¼å¼è½¬æ¢ä¸ºPytorchå¼ é‡ HxWxC -> CxHxW;
     # å°†uint8(0-255) -> float32; å½’ä¸€åŒ– ç¼©æ”¾åˆ°[0.0,1.0]
     transforms.Normalize((0.5,), (0.5,))  # æ¯ä¸ªé€šé“å‡å€¼0.5 æ–¹å·®0.5 çš„æ ‡å‡†åŒ–(å½’ä¸€åŒ–) output=(input-mean)/std
     ]
)
# transforms.Composeå †å å›¾åƒé¢„å¤„ç†æ­¥éª¤

img = Image.open('./image/dogs/1st_t.jpg')
img = transform(img).unsqueeze(0)  # [C,H,W] ->[N,C,H,W] Nä¸ºbatchæ‰¹æ¬¡æ•°é‡ï¼Œä¸€æ¬¡å¤„ç†å›¾åƒæ•°é‡

CIFAR10_CLASSES = ["airplane", "automobile", "bird", "cat", "deer",
                   "dog", "frog", "horse", "ship", "truck"]

with torch.no_grad():
    output = model(img)
    probabilities = F.softmax(output, dim=1)  # è®¡ç®—æ‰€æœ‰ç±»åˆ«çš„æ¦‚ç‡
    predicted = torch.argmax(output, dim=1).item()  # åœ¨ç¬¬dimä¸ªç»´åº¦(è¡Œï¼‰ä¸ŠæŸ¥æ‰¾æœ€å¤§å€¼ï¼Œè¿”å›æ¯ä¸€è¡Œæœ€å¤§å€¼çš„åˆ—ç´¢å¼•
# torch.no_gradç¦ç”¨æ¢¯åº¦è¿ç®—ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼ŒåŠ é€Ÿè®¡ç®—å‡å°‘æ˜¾å­˜å ç”¨ ï¼ˆæ¢¯åº¦è¿ç®—æŒ‡å¾®åˆ†ï¼Œä¼˜åŒ–æ¨¡å‹ï¼Œå‚æ•°æ›´æ–°æ–¹å‘ä¸æ¢¯åº¦æ–¹å‘ç›¸åï¼‰
print(f'é¢„æµ‹ç±»åˆ«: {predicted}({CIFAR10_CLASSES[predicted]})')
print(f'é¢„æµ‹æ¦‚ç‡åˆ†å¸ƒï¼š{probabilities.squeeze()}')
"""CIFAR-10 çš„ç±»åˆ«å¯¹åº”è¡¨ï¼š
ç±»åˆ«ç¼–å·	çœŸå®ç±»åˆ«
0	ğŸ›µ é£æœº (airplane)
1	ğŸš— æ±½è½¦ (automobile)
2	ğŸ¢ é¸Ÿ (bird)
3	ğŸ± çŒ« (cat)
4	ğŸ¦Œ é¹¿ (deer)
5	ğŸ• ç‹— (dog)
6	ğŸ¸ é’è›™ (frog)
7	ğŸ é©¬ (horse)
8	ğŸš¢ èˆ¹ (ship)
9	ğŸšš å¡è½¦ (truck)"""
